{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start/ importing begging libraries\n",
    "import requests\n",
    "import json\n",
    "import csv  \n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "print(\"yn = yes or no\")\n",
    "print(\"green fn\")\n",
    "print(\"yellow fn\")\n",
    "print(\"red fn\")\n",
    "print(\"blue fn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#california natural resource agency \n",
    "\n",
    "url = 'https://data.cnra.ca.gov/api/3/action/datastore_search?resource_id=8ea91e09-3c84-4eba-9489-3ab3b08adfd0&limit=10000' \n",
    "# Send a GET request to the API\n",
    "response = requests.get(url)\n",
    "# Parse the JSON response\n",
    "response_dict = response.json()\n",
    "filtered_records = []\n",
    "# Accessing records and printing the value of YEAR_ for each record\n",
    "if \"result\" in response_dict and \"records\" in response_dict[\"result\"]:\n",
    "    for record in  response_dict[\"result\"][\"records\"]:\n",
    "        year_value = record.get(\"YEAR_\")  # Access YEAR_ from each record\n",
    "        try:\n",
    "            # Only print the entire record where YEAR_ is 2000 or later\n",
    "            if int(year_value) >= 2000:\n",
    "               filtered_records.append(record)\n",
    "        except (ValueError, TypeError):\n",
    "            # Skip :ecords where YEAR_ is not a valid number\n",
    "            continue\n",
    "\n",
    "df = pd.DataFrame(filtered_records)\n",
    "df.to_csv('cnra_data.csv', index=False, encoding='utf-8')\n",
    "# Write the DataFrame to a CSV file\n",
    "# filter the data by alarm_date\n",
    "\n",
    "df1 = pd.read_csv('dont_delete/cnra_data.csv') # read the csv file\n",
    "df1['ALARM_DATE'] = pd.to_datetime(df1['ALARM_DATE'], errors='coerce') # convert the alarm_date column to datetime\n",
    "#df1['ALARM_DATE'] = df1['ALARM_DATE'].dt.tz_convert('UTC')\n",
    "df1_sorted = df1.sort_values(by = 'ALARM_DATE', ascending=False) # filter the data by alarm_date\n",
    "df1_sorted.to_csv('exported_data/cnra_data_sorted.csv', index=False) # save the filtered data to a new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order by incident_date_created  \n",
    "# Read the CSV file\n",
    "df2 = pd.read_csv('dont_delete/fire_ca.csv')\n",
    "fire = df2[df2['incident_name'].str.contains('Fire', case=False, na=False)].copy()\n",
    "# copying onlie fire data\n",
    "# Convert 'incident_date_created' to datetime, coercing errors to NaT\n",
    "fire['incident_date_created'] = pd.to_datetime(fire['incident_date_created'], errors='coerce')\n",
    "# Sort by 'incident_date_created' in descending order\n",
    "df_sorted = fire.sort_values(by='incident_date_created', ascending=False)\n",
    "# Save the sorted DataFrame to a new CSV file\n",
    "df_sorted.to_csv('sorted_by_year.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('exported_data/cnra_data_sorted.csv')\n",
    "        \n",
    "    # Remove multiple columns\n",
    "columns_to_remove = ['OBJECTID', '_id', 'YEAR_','STATE','AGENCY','UNIT_ID','INC_NUM','OBJECTIVE','COMMENTS','IRWINID','FIRE_NUM','DECADES','COMPLEX_ID']\n",
    "# OBJECTID\n",
    "#_id\n",
    "# YEAR_\n",
    "# STATE\n",
    "# AGENCY \n",
    "# UNIT_ID\n",
    "\n",
    "# INC_NUM\n",
    "# OBJECTIVE \n",
    "# COMMENTS \n",
    "# IRWINID \n",
    "# FIRE_NUM\n",
    "# COMPLEX_ID \n",
    "# DECADES\n",
    "\n",
    "df.drop(columns=columns_to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVC Bands: ['EVC']\n",
      "EVT Bands: ['EVT']\n",
      "\n",
      "EVC Value (Cover %): 103\n",
      "EVT Value (Type Code): 3921\n",
      "\n",
      "Biomass Value: 1.9107507467269897\n",
      "Confidence Value: 36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{firename,lat,lon}  [evt,evc,[biomass,confidence]]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'this gets the data from google earth engine from landfire,'\n",
    "'we will make it so that we collect the vegetation type(returns a value corresponding to the vegation)'\n",
    "'the evc is the vegation cover, this returns a code corresponding to vegetation look at the landfire documentation for more information'\n",
    "\n",
    "import ee\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize EE\n",
    "ee.Initialize(project='fuzz-464001')\n",
    "# Define a point (Northern California coastal area)\n",
    "point = ee.Geometry.Point([-120.87, 41.44])\n",
    "# Load LANDFIRE datasets (corrected case sensitivity)\n",
    "evc_image = ee.Image('LANDFIRE/Vegetation/EVC/v1_4_0/CONUS')\n",
    "evt_image = ee.Image('LANDFIRE/Vegetation/EVT/v1_4_0/CONUS')  # <- Corrected\n",
    "# Print band names\n",
    "#print(evc_image)\n",
    "print(\"EVC Bands:\", evc_image.bandNames().getInfo())  # Should show ['EVC']\n",
    "print(\"EVT Bands:\", evt_image.bandNames().getInfo())  # Should show ['EVT']\n",
    "# Get pixel values\n",
    "evc_result = evc_image.reduceRegion(\n",
    "    reducer=ee.Reducer.first(),\n",
    "    geometry=point,\n",
    "    scale=30  # 30m resolution\n",
    ").getInfo()  # Directly get the Python dictionary\n",
    "\n",
    "evt_result = evt_image.reduceRegion(\n",
    "    reducer=ee.Reducer.first(),\n",
    "    geometry=point,\n",
    "    scale=30\n",
    ").getInfo()\n",
    "\n",
    "print(\"\\nEVC Value (Cover %):\", evc_result['EVC'])\n",
    "print(\"EVT Value (Type Code):\", evt_result['EVT'])\n",
    "\n",
    "\n",
    "image_biomass = ee.Image('LARSE/GEDI/GEDI04_B_002')\n",
    "layer1 = image_biomass.select('MU')\n",
    "biomass_result = layer1.reduceRegion(\n",
    "    reducer=ee.Reducer.first(),\n",
    "    geometry=point,\n",
    "    scale=30\n",
    ").getInfo()\n",
    "\n",
    "confidence_layer = image_biomass.select('PE')\n",
    "confidence_result = confidence_layer.reduceRegion(\n",
    "    reducer=ee.Reducer.first(),\n",
    "    geometry=point,\n",
    "    scale=30\n",
    ").getInfo()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "' for this we are going to use the GEDI dataset, which provides biomass and confidence values'\n",
    "''\n",
    "\n",
    "'how much biomass is bad in the area'\n",
    "'VERY low amount of bioass = 0-10 MG/ha'\n",
    "'medium amount of biomass = 10-50 MG/ha'\n",
    "'medium to high amount of biomass = 50-150 MG/ha'\n",
    "'high amount of biomass = 150+ MG/ha  forest area'\n",
    "\n",
    "'LOWER MEANS BAD 0-50'\n",
    "'80-100 PERCENT CONFIDENCE IS GOOD'\n",
    "\n",
    "\n",
    "'high amount of biomass = '\n",
    "print(\"\\nBiomass Value:\", biomass_result['MU'])\n",
    "print(\"Confidence Value:\", confidence_result['PE'])\n",
    "\n",
    "\n",
    "'{firename,lat,lon}  [evt,evc,[biomass,confidence]]'\n",
    "\n",
    "\n",
    "'include building material for each fire, for the model incorporate the building material uncertanty to account for brickk and other non flammable materials'\n",
    "'using microsoft building footprint data'\n",
    "\n",
    "\n",
    "ee.features.FeatureCollection('Microsoft/USBuildingFootprints/CONUS')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
